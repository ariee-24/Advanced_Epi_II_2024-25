{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf8654c36783a2c",
   "metadata": {},
   "source": [
    "# Exercise: Predicting Customer Churn with a Neural Network\n",
    "\n",
    "You are provided with a real-world dataset from a telecom company that includes information about their customers, such as services signed up for, contract type, and payment behavior. Your task is to build a simple neural network to predict whether a customer will churn (i.e., leave the company) or not.\n",
    "\n",
    "## Task\n",
    "Build, train, and evaluate a neural network that predicts whether a customer has churned (`Churn` = Yes) or not (`Churn` = No), based on the other available features in the dataset.\n",
    "\n",
    "1. **Drop irrelevant columns**, which have no numerical meaning.\n",
    "2. **Convert columns** to numeric. There may be non-numeric entries; handle them appropriately (e.g. by coercing errors and dropping missing values).\n",
    "3. **Convert the target column** from categorical (\"Yes\"/\"No\") to binary (1/0).\n",
    "4. **Encode categorical features** using the `get_dummies`-function.\n",
    "5. **Prepare your data** before you feed it into your model.\n",
    "6. **Build a neural network** using Keras (e.g., with 1–3 layers) to predict churn.\n",
    "7. **Compile your model** with an appropriate loss function and optimizer.\n",
    "8. **Train your model** on the training data. \n",
    "9. **Evaluate the performance** of your model on the test set and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf71709349a0df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d919e4346e688fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4978 - loss: 46.9334 - val_accuracy: 0.7858 - val_loss: 0.6097\n",
      "Epoch 2/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7695 - loss: 0.5407 - val_accuracy: 0.7653 - val_loss: 0.5108\n",
      "Epoch 3/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.5100 - val_accuracy: 0.7947 - val_loss: 0.4794\n",
      "Epoch 4/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7545 - loss: 0.8783 - val_accuracy: 0.7751 - val_loss: 0.4653\n",
      "Epoch 5/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.5281 - val_accuracy: 0.8000 - val_loss: 0.4716\n",
      "Epoch 6/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.5426 - val_accuracy: 0.7991 - val_loss: 0.4308\n",
      "Epoch 7/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 0.5332 - val_accuracy: 0.8053 - val_loss: 0.4140\n",
      "Epoch 8/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.4944 - val_accuracy: 0.8071 - val_loss: 0.4102\n",
      "Epoch 9/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.4734 - val_accuracy: 0.7618 - val_loss: 0.4543\n",
      "Epoch 10/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4718 - val_accuracy: 0.8000 - val_loss: 0.4783\n",
      "Epoch 11/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.5743 - val_accuracy: 0.8053 - val_loss: 0.4560\n",
      "Epoch 12/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7940 - loss: 0.4775 - val_accuracy: 0.8000 - val_loss: 0.4944\n",
      "Epoch 13/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7794 - loss: 0.5204 - val_accuracy: 0.7858 - val_loss: 0.4296\n",
      "Epoch 14/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7796 - loss: 0.5213 - val_accuracy: 0.6400 - val_loss: 0.6830\n",
      "Epoch 15/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.5231 - val_accuracy: 0.6204 - val_loss: 0.7601\n",
      "Epoch 16/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7531 - loss: 0.6925 - val_accuracy: 0.7796 - val_loss: 0.4354\n",
      "Epoch 17/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.5295 - val_accuracy: 0.7867 - val_loss: 0.9395\n",
      "Epoch 18/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.5531 - val_accuracy: 0.7831 - val_loss: 0.5179\n",
      "Epoch 19/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.5225 - val_accuracy: 0.8187 - val_loss: 0.3988\n",
      "Epoch 20/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4508 - val_accuracy: 0.8116 - val_loss: 0.4014\n",
      "Epoch 21/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.4672 - val_accuracy: 0.8196 - val_loss: 0.3982\n",
      "Epoch 22/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4615 - val_accuracy: 0.7991 - val_loss: 0.5357\n",
      "Epoch 23/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.5368 - val_accuracy: 0.8009 - val_loss: 0.4549\n",
      "Epoch 24/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7681 - loss: 0.6211 - val_accuracy: 0.8089 - val_loss: 0.3998\n",
      "Epoch 25/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.4556 - val_accuracy: 0.8196 - val_loss: 0.3981\n",
      "Epoch 26/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.5241 - val_accuracy: 0.7991 - val_loss: 0.4171\n",
      "Epoch 27/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4744 - val_accuracy: 0.8169 - val_loss: 0.4107\n",
      "Epoch 28/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.4594 - val_accuracy: 0.8169 - val_loss: 0.4016\n",
      "Epoch 29/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4468 - val_accuracy: 0.8062 - val_loss: 0.4475\n",
      "Epoch 30/30\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4967 - val_accuracy: 0.8027 - val_loss: 0.4132\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Neural Network Accuracy: 0.7733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1033\n",
      "           1       0.57      0.63      0.60       374\n",
      "\n",
      "    accuracy                           0.77      1407\n",
      "   macro avg       0.71      0.73      0.72      1407\n",
      "weighted avg       0.78      0.77      0.78      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Drop irrelevant column \"customerID\"\n",
    "df = df.drop(columns=[\"customerID\"])\n",
    "\n",
    "# Clean \"TotalCharges\" column: convert to numeric, coerce errors to NaN and drop those rows\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"TotalCharges\"])\n",
    "\n",
    "# Convert the target column\n",
    "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Identify categorical variables\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Split into features and target\n",
    "X = df_encoded.drop(\"Churn\", axis=1)\n",
    "y = df_encoded[\"Churn\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a neural network model\n",
    "model = Sequential([\n",
    "    Dense(32, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f\"Neural Network Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
